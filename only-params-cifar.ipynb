{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install thop\n!pip install timm","metadata":{"execution":{"iopub.status.busy":"2024-04-12T06:54:57.218652Z","iopub.execute_input":"2024-04-12T06:54:57.219575Z","iopub.status.idle":"2024-04-12T06:55:28.572142Z","shell.execute_reply.started":"2024-04-12T06:54:57.219536Z","shell.execute_reply":"2024-04-12T06:55:28.570693Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting thop\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from thop) (2.1.2+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->thop) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->thop) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->thop) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->thop) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->thop) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->thop) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->thop) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->thop) (1.3.0)\nDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nInstalling collected packages: thop\nSuccessfully installed thop-0.1.1.post2209072238\nRequirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.16)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2+cpu)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.22.2)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub->timm) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->timm) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->timm) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub->timm) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->timm) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport torch.optim as optim\nfrom torch.utils.tensorboard import SummaryWriter  # Import for TensorBoard visualization (optional)\nimport torch\nfrom torch import nn\nfrom timm import create_model\nfrom torch import nn\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom timm import create_model  # Import for Swin Transformer\n\n# Model and pruning configuration (adjust as needed)\nmodel_name = \"swin_tiny_patch4_window7_224\"  # Choose the desired Swin Transformer model\npruning_ratio = 0.3  # Start with lower pruning ratios\nnum_training_epochs = 3  # Train longer before pruning\nnum_finetuning_epochs = 2  # Fine-tune longer to recover\nlearning_rate = 0.002  # Slightly lower learning rate\nlearning_rate_finetune = 0.001  # Fine-tuning learning rate\nthreshold = 0.3  \n\n\n# Load dataset and apply appropriate transformations\ntransform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\ntest_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n\nimport torch\nfrom torch import nn\nfrom timm import create_model\n\n\n\n\n\n    \n\ndef count_model_parameters(model: nn.Module) -> int:\n    \"\"\"\n    Counts the total number of non-zero parameters in a PyTorch model.\n\n    Args:\n        model (nn.Module): The PyTorch model to count the non-zero parameters of.\n\n    Returns:\n        int: The total number of non-zero parameters in the model.\n    \"\"\"\n\n    total_non_zero_params = 0\n    for param in model.parameters():\n        # Count non-zero elements using torch.count_nonzero for efficiency\n        total_non_zero_params += torch.count_nonzero(param).item()\n\n    return total_non_zero_params\n\n\n\ndef prune_model_with_svd_and_iht(model, pruning_ratio, num_iterations=10):\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Linear):\n            print(\"Processing layer:\", name)\n            weight = module.weight.data\n            # Apply SVD\n            print(\"Applying SVD...\")\n            u, s, v = torch.svd(weight)\n            s_pruned = torch.zeros_like(s)\n            s_pruned[:int(s.size(0) * (1 - pruning_ratio))] = s[:int(s.size(0) * (1 - pruning_ratio))]\n            weight_pruned_svd = torch.mm(u, torch.mm(torch.diag(s_pruned), v.t()))\n            num_params_after_svd = count_model_parameters(model)\n            print(\"Number of parameters after SVD pruning:\", count_model_parameters(model))\n\n            print(f\"Number of parameters after svd pruning: {num_params_after_svd}\")\n          # Apply IHT with masking for better pruning\n            print(\"Applying IHT...\")\n            weight_pruned_iht = iht(weights=weight_pruned_svd, pruning_ratio=pruning_ratio,\n                                    num_iterations=num_iterations, threshold=threshold, module=module)\n            \n            # Set the pruned weights and clear gradients (important for training)\n            module.weight.data = weight_pruned_iht\n            module.weight.grad = None\n\ndef iht(weights, pruning_ratio, num_iterations, threshold, module):\n    for _ in range(num_iterations):\n        # Calculate gradients using torch.autograd.grad with retain_graph=True to avoid recomputing previous gradients\n        gradients = torch.autograd.grad(module.weight, module.weight, grad_outputs=weights, retain_graph=True)[0]\n\n        # Update weights using calculated gradients, masking to avoid overwriting pruned values\n        mask = torch.abs(weights) >= threshold\n        weights[mask] = torch.clamp(weights[mask] - learning_rate * gradients[mask], -threshold, threshold)\n\n    # Apply hard thresholding and clear gradients\n    weights[torch.abs(weights) < threshold] = 0\n    weights.grad = None\n    num_params_after_svdandiht = count_model_parameters(model)\n    print(f\"Number of parameters after svdandiht pruning: {num_params_after_svdandiht}\")\n\n    return weights\n\n\n\n\ndef optimizer_creator():\n    return torch.optim.SGD(model.parameters(), lr=learning_rate)  # Create optimizer within a closure\n\n# Load the model once before the loop\nmodel = create_model(model_name, pretrained=True)\ninput_size = (16, 3, 224, 224) \n\noptimizer = optimizer_creator()\ncriterion = nn.CrossEntropyLoss()\nfor epoch in range(num_training_epochs):\n    train_loss = 0.0\n    train_acc = 0.0\n    for images, labels in train_loader:\n        optimizer.zero_grad()  # Clear gradients for the current step\n        outputs = model(images)\n        logits = outputs  # Access logits for Swin Transformers\n        loss = criterion(logits, labels)\n        loss.backward()  # Backpropagate gradients\n        optimizer.step()  # Update model parameters based on gradients\n        train_loss += loss.item()  # Accumulate training loss\n\n        \n        # Calculate training accuracy\n        _, preds = torch.max(outputs, 1)\n        train_acc += torch.sum(preds == labels).item() / len(labels)\n\n    # Print training progress\n    print(f\"Epoch [{epoch+1}/{num_training_epochs}], Pruning Ratio: {pruning_ratio:.2f}, \"\n            f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc/len(train_loader):.4f}\")\n\n\nnum_params_before = count_model_parameters(model)\nprint(f\"Number of parameters before pruning: {num_params_before}\")\n\nprune_model_with_svd_and_iht(model, pruning_ratio=pruning_ratio)\n\n\n # Fine-tune the pruned model\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate_finetune)  # Adjust learning rate\nfor epoch in range(num_finetuning_epochs):\n    train_loss = 0.0\n    train_acc = 0.0\n    for images, labels in train_loader:\n        optimizer.zero_grad()  # Clear gradients for the current step\n        outputs = model(images)\n        logits = outputs  # Access logits for Swin Transformers\n        loss = criterion(logits, labels)\n        loss.backward()  # Backpropagate gradients\n        optimizer.step()  # Update model parameters based on gradients\n        train_loss += loss.item()  # Accumulate training loss\n\n        # Calculate training accuracy\n        _, preds = torch.max(outputs, 1)\n        train_acc += torch.sum(preds == labels).item() / len(labels)\n\n    # Print training progress\n    print(f\"Fine-tuning Epoch [{epoch + 1}/{num_finetuning_epochs}], Pruning Ratio: {pruning_ratio:.2f}, \"\n          f\"Train Loss: {train_loss / len(train_loader):.4f}, Train Acc: {train_acc / len(train_loader):.4f}\")\n\n\n# Evaluate pruned model accuracy on the test set\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for images, labels in test_loader:\n        outputs = model(images)\n    _, predicted = torch.max(outputs.data, 1)  # Corrected indentation\n    total += labels.size(0)\n    correct += (predicted == labels).sum().item()\npruned_accuracy = 100 * correct / total\nprint(f\"Accuracy after pruning {pruning_ratio:.2f}: {pruned_accuracy:.2f}%\")\n","metadata":{},"execution_count":null,"outputs":[]}]}