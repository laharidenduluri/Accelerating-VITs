{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efbaca08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T05:16:10.615611Z",
     "iopub.status.busy": "2024-02-16T05:16:10.615264Z",
     "iopub.status.idle": "2024-02-16T05:16:32.715011Z",
     "shell.execute_reply": "2024-02-16T05:16:32.714047Z"
    },
    "papermill": {
     "duration": 22.105799,
     "end_time": "2024-02-16T05:16:32.717287",
     "exception": false,
     "start_time": "2024-02-16T05:16:10.611488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\r\n",
      "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\r\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/2.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 23.3.2\r\n",
      "    Uninstalling pip-23.3.2:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled pip-23.3.2\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed pip-24.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0867d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T05:16:32.724348Z",
     "iopub.status.busy": "2024-02-16T05:16:32.724003Z",
     "iopub.status.idle": "2024-02-16T05:16:44.913721Z",
     "shell.execute_reply": "2024-02-16T05:16:44.912753Z"
    },
    "papermill": {
     "duration": 12.195885,
     "end_time": "2024-02-16T05:16:44.916106",
     "exception": false,
     "start_time": "2024-02-16T05:16:32.720221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.12)\r\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.3)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (2023.12.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.66.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (21.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.24.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.5.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.1.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.11.17)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e5bc17b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T05:16:44.924523Z",
     "iopub.status.busy": "2024-02-16T05:16:44.923769Z",
     "iopub.status.idle": "2024-02-16T05:16:45.572849Z",
     "shell.execute_reply": "2024-02-16T05:16:45.571842Z"
    },
    "papermill": {
     "duration": 0.65577,
     "end_time": "2024-02-16T05:16:45.575240",
     "exception": false,
     "start_time": "2024-02-16T05:16:44.919470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32452c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T05:16:45.583742Z",
     "iopub.status.busy": "2024-02-16T05:16:45.582972Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-02-16T05:16:45.578710",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/170498071 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 65536/170498071 [00:00<04:44, 598226.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 229376/170498071 [00:00<02:28, 1146432.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  1%|          | 917504/170498071 [00:00<00:48, 3496321.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  2%|▏         | 3670016/170498071 [00:00<00:13, 12023151.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  5%|▍         | 7766016/170498071 [00:00<00:07, 21154486.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  7%|▋         | 11796480/170498071 [00:00<00:05, 27265894.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  9%|▉         | 15532032/170498071 [00:00<00:05, 30421103.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 11%|█         | 19136512/170498071 [00:00<00:04, 31994926.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 13%|█▎        | 22872064/170498071 [00:00<00:04, 33611812.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 16%|█▌        | 26509312/170498071 [00:01<00:04, 34447053.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 18%|█▊        | 30343168/170498071 [00:01<00:03, 35578871.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|██        | 34340864/170498071 [00:01<00:03, 36157933.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 23%|██▎       | 38371328/170498071 [00:01<00:03, 36444862.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 25%|██▍       | 42401792/170498071 [00:01<00:03, 36641987.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 27%|██▋       | 46530560/170498071 [00:01<00:03, 36977141.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 30%|██▉       | 50659328/170498071 [00:01<00:03, 37168094.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 32%|███▏      | 54755328/170498071 [00:01<00:03, 37534347.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 34%|███▍      | 58785792/170498071 [00:01<00:02, 38291823.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 37%|███▋      | 62619648/170498071 [00:02<00:02, 37927266.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 39%|███▉      | 66420736/170498071 [00:02<00:02, 37398883.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 41%|████      | 70189056/170498071 [00:02<00:02, 37470874.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 43%|████▎     | 73957376/170498071 [00:02<00:02, 37153685.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 46%|████▌     | 77692928/170498071 [00:02<00:02, 36961876.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 48%|████▊     | 81690624/170498071 [00:02<00:02, 37727716.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|█████     | 85557248/170498071 [00:02<00:02, 37806460.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 52%|█████▏    | 89456640/170498071 [00:02<00:02, 38125975.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 55%|█████▍    | 93290496/170498071 [00:02<00:02, 37636367.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 57%|█████▋    | 97058816/170498071 [00:02<00:01, 37229276.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 59%|█████▉    | 100859904/170498071 [00:03<00:01, 37444502.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 61%|██████▏   | 104628224/170498071 [00:03<00:01, 37020270.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 64%|██████▎   | 108494848/170498071 [00:03<00:01, 37284271.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 66%|██████▌   | 112394240/170498071 [00:03<00:01, 37648518.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 68%|██████▊   | 116326400/170498071 [00:03<00:01, 38129252.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 70%|███████   | 120160256/170498071 [00:03<00:01, 37913228.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 73%|███████▎  | 123961344/170498071 [00:03<00:01, 37362655.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 75%|███████▍  | 127729664/170498071 [00:03<00:01, 37333639.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 77%|███████▋  | 131465216/170498071 [00:03<00:01, 37211635.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 79%|███████▉  | 135200768/170498071 [00:03<00:00, 37082092.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 82%|████████▏ | 139132928/170498071 [00:04<00:00, 37694792.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 84%|████████▍ | 142999552/170498071 [00:04<00:00, 37619123.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 86%|████████▌ | 146833408/170498071 [00:04<00:00, 37690527.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 88%|████████▊ | 150634496/170498071 [00:04<00:00, 37719671.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 91%|█████████ | 154435584/170498071 [00:04<00:00, 37405287.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 93%|█████████▎| 158203904/170498071 [00:04<00:00, 37395334.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 95%|█████████▍| 161972224/170498071 [00:04<00:00, 37263285.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 97%|█████████▋| 165740544/170498071 [00:04<00:00, 36773712.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "100%|█████████▉| 169771008/170498071 [00:04<00:00, 37515161.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "100%|██████████| 170498071/170498071 [00:04<00:00, 34895954.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe02c0715aef493bb904f1cdc39b122c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Pruning Ratio: 0.10, Train Loss: 0.5344, Train Acc: 0.8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Pruning Ratio: 0.10, Train Loss: 0.1451, Train Acc: 0.9502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Pruning Ratio: 0.10, Train Loss: 0.0985, Train Acc: 0.9664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Pruning Ratio: 0.10, Train Loss: 0.0749, Train Acc: 0.9747\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from timm import create_model  # Import for Swin Transformer\n",
    "\n",
    "# Model and pruning configuration (adjust as needed)\n",
    "model_name = \"swin_tiny_patch4_window7_224\"  # Choose the desired Swin Transformer model\n",
    "pruning_schedule = [0.1, 0.2, 0.3, 0.4]  # Start with lower pruning ratios\n",
    "num_training_epochs = 10  # Train longer before pruning\n",
    "num_finetuning_epochs = 20  # Fine-tune longer to recover\n",
    "learning_rate = 0.003  # Slightly lower learning rate\n",
    "learning_rate_finetune = 0.001  # Fine-tuning learning rate\n",
    "threshold = 0.4  # Adjust threshold for IHT if needed\n",
    "\n",
    "# Load dataset and apply appropriate transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "def prune_model_with_svd_and_iht(model, pruning_ratio, num_iterations=10):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            weight = module.weight.data\n",
    "\n",
    "            # Apply SVD\n",
    "            u, s, v = torch.svd(weight)\n",
    "            s_pruned = torch.zeros_like(s)\n",
    "            s_pruned[:int(s.size(0) * (1 - pruning_ratio))] = s[:int(s.size(0) * (1 - pruning_ratio))]\n",
    "            weight_pruned_svd = torch.mm(u, torch.mm(torch.diag(s_pruned), v.t()))\n",
    "\n",
    "            # Apply IHT\n",
    "            weight_pruned_iht = iht(weights=weight_pruned_svd, pruning_ratio=pruning_ratio,\n",
    "                                   num_iterations=num_iterations, threshold=threshold, module=module)\n",
    "\n",
    "            # Combine pruning methods (e.g., average)\n",
    "            weight_pruned = (weight_pruned_svd + weight_pruned_iht) / 2\n",
    "\n",
    "            module.weight.data = weight_pruned  # Apply the pruned weights\n",
    "\n",
    "\n",
    "def iht(weights, pruning_ratio, num_iterations, threshold, module):\n",
    "    for _ in range(num_iterations):\n",
    "        # Calculate gradients using torch.autograd.grad\n",
    "        gradients = torch.autograd.grad(module.weight, module.weight, grad_outputs=weights)[0]\n",
    "\n",
    "        # Update weights using calculated gradients\n",
    "        weights = torch.clamp(weights - learning_rate * gradients, -threshold, threshold)\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Load the model once before the loop\n",
    "model = create_model(model_name, pretrained=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  # Define the optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Define the loss function\n",
    "\n",
    "\n",
    "# Initialize overall accuracy tracking\n",
    "overall_accuracy = 0.0\n",
    "num_iterations = 0\n",
    "\n",
    "for pruning_ratio in pruning_schedule:\n",
    "    # Train for a few epochs before pruning\n",
    "    for epoch in range(num_training_epochs):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()  # Clear gradients for the current step\n",
    "            outputs = model(images)\n",
    "            logits = outputs # Access logits for Swin Transformers\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()  # Backpropagate gradients\n",
    "            optimizer.step()  # Update model parameters based on gradients\n",
    "            train_loss += loss.item()  # Accumulate training loss\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            train_acc += torch.sum(preds == labels).item() / len(labels)\n",
    "\n",
    "        # Print training progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_training_epochs}], Pruning Ratio: {pruning_ratio:.2f}, \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc/len(train_loader):.4f}\")\n",
    "\n",
    "    # Apply pruning with the current pruning ratio\n",
    "    prune_model_with_svd_and_iht(model, pruning_ratio=pruning_ratio)\n",
    "\n",
    "    # Fine-tune the pruned model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate_finetune)  # Adjust learning rate\n",
    "for epoch in range(num_finetuning_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Clear gradients for the current step\n",
    "        outputs = model(images)\n",
    "        logits = outputs  # Access logits for Swin Transformers\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()  # Backpropagate gradients\n",
    "        optimizer.step()  # Update model parameters based on gradients\n",
    "        train_loss += loss.item()  # Accumulate training loss\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_acc += torch.sum(preds == labels).item() / len(labels)\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"Fine-tuning Epoch [{epoch + 1}/{num_finetuning_epochs}], Pruning Ratio: {pruning_ratio:.2f}, \"\n",
    "          f\"Train Loss: {train_loss / len(train_loader):.4f}, Train Acc: {train_acc / len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "    # Evaluate pruned model accuracy on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "  for images, labels in test_loader:\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.logits.data, 1)  # Corrected indentation\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "pruned_accuracy = 100 * correct / total\n",
    "print(f\"Accuracy after pruning {pruning_ratio:.2f}: {pruned_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-16T05:16:07.944404",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
