{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7586f079",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-24T16:54:48.281201Z",
     "iopub.status.busy": "2024-02-24T16:54:48.280816Z",
     "iopub.status.idle": "2024-02-24T16:54:48.977069Z",
     "shell.execute_reply": "2024-02-24T16:54:48.975904Z"
    },
    "papermill": {
     "duration": 0.702197,
     "end_time": "2024-02-24T16:54:48.979505",
     "exception": false,
     "start_time": "2024-02-24T16:54:48.277308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b934bac2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-24T16:54:48.985019Z",
     "iopub.status.busy": "2024-02-24T16:54:48.984597Z",
     "iopub.status.idle": "2024-02-25T04:17:34.138974Z",
     "shell.execute_reply": "2024-02-25T04:17:34.137874Z"
    },
    "papermill": {
     "duration": 40965.168947,
     "end_time": "2024-02-25T04:17:34.150496",
     "exception": false,
     "start_time": "2024-02-24T16:54:48.981549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:10<00:00, 16122659.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e969228a54fe40aab89d4a7d500c49fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters before pruning: 28288354\n",
      "Epoch [1/2], Pruning Ratio: 0.40, Train Loss: 0.5846, Train Acc: 0.8070\n",
      "Epoch [2/2], Pruning Ratio: 0.40, Train Loss: 0.1518, Train Acc: 0.9491\n",
      "Number of parameters after pruning with ratio 0.40: 28288354\n",
      "Fine-tuning Epoch [1/2], Pruning Ratio: 0.40, Train Loss: 0.1614, Train Acc: 0.9460\n",
      "Fine-tuning Epoch [2/2], Pruning Ratio: 0.40, Train Loss: 0.1134, Train Acc: 0.9612\n",
      "Accuracy after pruning 0.40: 95.27%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from timm import create_model  # Import for Swin Transformer\n",
    "\n",
    "# Model and pruning configuration (adjust as needed)\n",
    "model_name = \"swin_tiny_patch4_window7_224\"  # Choose the desired Swin Transformer model\n",
    "pruning_ratio = 0.4  # Start with lower pruning ratios\n",
    "num_training_epochs = 2  # Train longer before pruning\n",
    "num_finetuning_epochs = 2  # Fine-tune longer to recover\n",
    "learning_rate = 0.003  # Slightly lower learning rate\n",
    "learning_rate_finetune = 0.001  # Fine-tuning learning rate\n",
    "threshold = 0.4  \n",
    "\n",
    "# Load dataset and apply appropriate transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "def count_model_parameters(model):\n",
    "    \"\"\"\n",
    "    This function counts the total number of parameters in a PyTorch model.\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            total_params += torch.count_nonzero(param)\n",
    "    return total_params\n",
    "\n",
    "def prune_model_with_svd_and_iht(model, pruning_ratio, num_iterations=10):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            weight = module.weight.data\n",
    "\n",
    "            # Apply SVD\n",
    "            u, s, v = torch.svd(weight)\n",
    "            s_pruned = torch.zeros_like(s)\n",
    "            s_pruned[:int(s.size(0) * (1 - pruning_ratio))] = s[:int(s.size(0) * (1 - pruning_ratio))]\n",
    "            weight_pruned_svd = torch.mm(u, torch.mm(torch.diag(s_pruned), v.t()))\n",
    "\n",
    "            # Apply IHT\n",
    "            weight_pruned_iht = iht(weights=weight_pruned_svd, pruning_ratio=pruning_ratio,\n",
    "                                   num_iterations=num_iterations, threshold=threshold, module=module)\n",
    "\n",
    "            module.weight.data = weight_pruned_iht  # Apply the pruned weights\n",
    "\n",
    "\n",
    "def iht(weights, pruning_ratio, num_iterations, threshold, module):\n",
    "    for _ in range(num_iterations):\n",
    "        # Calculate gradients using torch.autograd.grad\n",
    "        gradients = torch.autograd.grad(module.weight, module.weight, grad_outputs=weights)[0]\n",
    "\n",
    "        # Update weights using calculated gradients\n",
    "        weights = torch.clamp(weights - learning_rate * gradients, -threshold, threshold)\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Load the model once before the loop\n",
    "model = create_model(model_name, pretrained=True)\n",
    "num_params_before = count_model_parameters(model)\n",
    "print(f\"Number of parameters before pruning: {num_params_before}\")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  # Define the optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Define the loss function\n",
    "\n",
    "\n",
    "# Initialize overall accuracy tracking\n",
    "overall_accuracy = 0.0\n",
    "num_iterations = 0\n",
    "\n",
    "for epoch in range(num_training_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Clear gradients for the current step\n",
    "        outputs = model(images)\n",
    "        logits = outputs # Access logits for Swin Transformers\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()  # Backpropagate gradients\n",
    "        optimizer.step()  # Update model parameters based on gradients\n",
    "        train_loss += loss.item()  # Accumulate training loss\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_acc += torch.sum(preds == labels).item() / len(labels)\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_training_epochs}], Pruning Ratio: {pruning_ratio:.2f}, \"\n",
    "            f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc/len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "# Apply pruning with the current pruning ratio\n",
    "prune_model_with_svd_and_iht(model, pruning_ratio=pruning_ratio)\n",
    "\n",
    "# Print parameter count after pruning\n",
    "num_params_after = count_model_parameters(model)\n",
    "print(f\"Number of parameters after pruning with ratio {pruning_ratio:.2f}: {num_params_after}\")\n",
    "\n",
    "    # Fine-tune the pruned model\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate_finetune)  # Adjust learning rate\n",
    "for epoch in range(num_finetuning_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()  # Clear gradients for the current step\n",
    "        outputs = model(images)\n",
    "        logits = outputs  # Access logits for Swin Transformers\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()  # Backpropagate gradients\n",
    "        optimizer.step()  # Update model parameters based on gradients\n",
    "        train_loss += loss.item()  # Accumulate training loss\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_acc += torch.sum(preds == labels).item() / len(labels)\n",
    "\n",
    "    # Print training progress\n",
    "    print(f\"Fine-tuning Epoch [{epoch + 1}/{num_finetuning_epochs}], Pruning Ratio: {pruning_ratio:.2f}, \"\n",
    "          f\"Train Loss: {train_loss / len(train_loader):.4f}, Train Acc: {train_acc / len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "# Evaluate pruned model accuracy on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # Corrected indentation\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    pruned_accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy after pruning {pruning_ratio:.2f}: {pruned_accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40970.672269,
   "end_time": "2024-02-25T04:17:36.166960",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-24T16:54:45.494691",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a582e563ddf41eaaf4683a0214bb797": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "561dc54871e84228bb8cf7a03f9181ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "59ac1491ab294788aa3f551e06fb708f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7466db4e27b742b4a5e2e7daf1cb2afb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "777f08e13b614d34992a6b33e114512b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7c99d93524f14da4838c3647b1aded28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a7bd054e7457469185d2f553b7dc4afe",
       "max": 114286722.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_777f08e13b614d34992a6b33e114512b",
       "value": 114286722.0
      }
     },
     "7facfe0770544bd694020760d2fb1aa8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6f375571919470da75bff883e36a5f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7facfe0770544bd694020760d2fb1aa8",
       "placeholder": "​",
       "style": "IPY_MODEL_0a582e563ddf41eaaf4683a0214bb797",
       "value": "model.safetensors: 100%"
      }
     },
     "a7bd054e7457469185d2f553b7dc4afe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2bae85a3edb4de08c24b9d310f882d2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59ac1491ab294788aa3f551e06fb708f",
       "placeholder": "​",
       "style": "IPY_MODEL_561dc54871e84228bb8cf7a03f9181ef",
       "value": " 114M/114M [00:01&lt;00:00, 79.3MB/s]"
      }
     },
     "e969228a54fe40aab89d4a7d500c49fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a6f375571919470da75bff883e36a5f8",
        "IPY_MODEL_7c99d93524f14da4838c3647b1aded28",
        "IPY_MODEL_c2bae85a3edb4de08c24b9d310f882d2"
       ],
       "layout": "IPY_MODEL_7466db4e27b742b4a5e2e7daf1cb2afb"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
